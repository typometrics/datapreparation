{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine separate analyse files\n",
    "- do not separate folders of the same language, because in statconll.py the results are computed by language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ ['f.tsv', 'cat.tsv', 'positive-direction.tsv', 'cf.tsv', 'cfc-dist.tsv', 'cf-dist.tsv', 'cfc.tsv', 'f-dist-noroot.tsv', 'posdircf.tsv', 'posdircfc.tsv', 'fc.tsv', 'f-dist.tsv', 'abs-f-dist-noroot.tsv'] \n",
      " -----\n"
     ]
    }
   ],
   "source": [
    "folders = [\"sud2.7-analysis\",\"cs_pdt-analysis\", \"de-hdt-analysis\", \"ja_bccwj-analysis\",\"ru_syntagrus-analysis\"]\n",
    "#\"sud2.7-analysis\" contains the most numbers of col name\n",
    "\n",
    "outputFolder = \"sud-treebanks-v2.7-analysis\"\n",
    "filesname = os.listdir(folders[0])\n",
    "print(\"------\",filesname, \"\\n -----\")\n",
    "     \n",
    "for folder in folders:\n",
    "    ck = os.listdir(folder)\n",
    "    assert(ck == filesname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f.tsv\n",
      "cat.tsv\n",
      "positive-direction.tsv\n",
      "cf.tsv\n",
      "cfc-dist.tsv\n",
      "cf-dist.tsv\n",
      "cfc.tsv\n",
      "f-dist-noroot.tsv\n",
      "posdircf.tsv\n",
      "posdircfc.tsv\n",
      "fc.tsv\n",
      "f-dist.tsv\n",
      "abs-f-dist-noroot.tsv\n"
     ]
    }
   ],
   "source": [
    "#find column name list that covers all the column names of files with the same filename\n",
    "colNamesDict = {}\n",
    "for fl in filesname:\n",
    "    print(fl)\n",
    "    colNames=[]\n",
    "    for i in range(len(folders)):\n",
    "        #print(folders[i])\n",
    "        with open(folders[i]+'/'+fl, 'r+',encoding=\"utf8\") as f:\n",
    "            line0 = f.readline().strip()\n",
    "            cols = line0.split('\\t')\n",
    "            #print(cols, '\\n')\n",
    "            colNames+= cols[1:]\n",
    "            \n",
    "    colNamesDict[fl] = sorted(list(set(colNames)))\n",
    "    #print('\\n for file ', fl, \"colnames = \", colNamesDict[fl], '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'appos': {}, 'cc': {}, 'clf': {}, 'comp': {}, 'comp:aux': {}, 'comp:cleft': {}, 'comp:obj': {}, 'comp:obl': {}, 'comp:pred': {}, 'compound': {}, 'compound:prt': {}, 'compound:redup': {}, 'compound:svc': {}, 'conj': {}, 'conj:appos': {}, 'conj:coord': {}, 'conj:dicto': {}, 'conj:emb': {}, 'conj:obj': {}, 'det': {}, 'det:num': {}, 'discourse': {}, 'dislocated': {}, 'flat': {}, 'flat:foreign': {}, 'flat:name': {}, 'goeswith': {}, 'list': {}, 'mod': {}, 'mod:appos': {}, 'mod:emph': {}, 'mod:num': {}, 'mod:periph': {}, 'mod:poss': {}, 'orphan': {}, 'parataxis': {}, 'parataxis:conj': {}, 'parataxis:discourse': {}, 'parataxis:dislocated': {}, 'parataxis:insert': {}, 'parataxis:obj': {}, 'parataxis:parenth': {}, 'punct': {}, 'reparandum': {}, 'subj': {}, 'total': {}, 'udep': {}, 'unk': {}, 'vocative': {}}\n"
     ]
    }
   ],
   "source": [
    "#prepare the dictionary info to combine information and to write in relevant files\n",
    "#print(colNamesDict['f.tsv'])\n",
    "info = {}\n",
    "for fl, colnames in colNamesDict.items():\n",
    "    info[fl]={}\n",
    "    for colname in colnames:\n",
    "        info[fl][colname]= {}\n",
    "\n",
    "print(info['f.tsv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f.tsv\n",
      "cat.tsv\n",
      "positive-direction.tsv\n",
      "cf.tsv\n",
      "cfc-dist.tsv\n",
      "cf-dist.tsv\n",
      "cfc.tsv\n",
      "f-dist-noroot.tsv\n",
      "posdircf.tsv\n",
      "posdircfc.tsv\n",
      "fc.tsv\n",
      "f-dist.tsv\n",
      "abs-f-dist-noroot.tsv\n",
      "{'Afrikaans': '0.00101', 'Assyrian': '0.0', 'SouthLevantineArabic': '0.0', 'Akkadian': '0.0728', 'Amharic': '0.0', 'Apurinã': '0.0', 'Akuntsu': '0.01408', 'Arabic': '0.0008', 'Belarusian': '0.01692', 'Bulgarian': '0.00018', 'Bhojpuri': '0.00013', 'Bambara': '0.00123', 'Breton': '0.0032', 'Buryat': '0.006', 'Catalan': '0.01133', 'Chukot': '0.00929', 'Coptic': '0.0055', 'OldChurchSlavonic': '0.00653', 'Welsh': '0.00412', 'Danish': '0.00296', 'Greek': '0.00355', 'English': '0.00474', 'Spanish': '0.01334', 'Estonian': '0.0069', 'Basque': '0.00401', 'Persian': '0.00201', 'Finnish': '0.00359', 'Faroese': '0.00381', 'French': '0.00523', 'OldFrench': '0.00321', 'Irish': '0.00244', 'Gaelic': '0.00262', 'Galician': '0.00038', 'Gothic': '0.01064', 'AncientGreek': '0.00571', 'SwissGerman': '0.00284', 'MbyáGuaraní': '0.00198', 'Manx': '0.00588', 'Hebrew': '0.00666', 'Hindi': '0.00022', 'Croatian': '0.00411', 'UpperSorbian': '0.01267', 'Hungarian': '0.00643', 'Armenian': '0.00444', 'Indonesian': '0.01651', 'Icelandic': '0.00772', 'Italian': '0.00383', 'Khunsari': '0.0', 'Kazakh': '0.00802', 'Kurmanji': '0.00247', 'Korean': '0.00547', 'Komi-Permyak': '0.00806', 'Komi': '0.0068', 'Karelian': '0.00566', 'Latin': '0.01398', 'Lithuanian': '0.00279', 'Latvian': '0.00174', 'ClassicalChinese': '0.0', 'Moksha': '0.00383', 'Marathi': '0.00071', 'Maltese': '0.00315', 'Mundurukú': '0.01569', 'Erzya': '0.00587', 'Dutch': '0.01118', 'Norwegian': '0.00268', 'Nayini': '0.0', 'Livvi': '0.00462', 'OldEastSlavic': '0.02305', 'OldTurkish': '0.0042', 'Naija': '0.0', 'Polish': '0.00433', 'Portuguese': '0.01365', 'HindiEnglish': '0.00036', 'TurkishGerman': '0.00234', 'Romanian': '0.00536', 'Sanskrit': '0.00425', 'Slovak': '0.00245', 'Slovenian': '0.00235', 'NorthSami': '0.00237', 'SkoltSami': '0.00462', 'Soi': '0.0', 'Albanian': '0.00094', 'Serbian': '0.00616', 'Swedish': '0.00385', 'SwedishSign': '0.00181', 'Tamil': '0.0', 'Telugu': '0.00034', 'Thai': '0.01272', 'Tagalog': '0.0', 'Tupinambá': '0.04054', 'Turkish': '0.00144', 'Uyghur': '0.00299', 'Ukrainian': '0.00618', 'Urdu': '0.0', 'Vietnamese': '0.00163', 'Warlpiri': '0.0', 'Wolof': '0.00534', 'Yoruba': '0.00206', 'Cantonese': '0.00303', 'Chinese': '0.0091', 'Czech': '0.00446', 'German': '0.01116', 'Russian': '0.00721'}\n"
     ]
    }
   ],
   "source": [
    "#combine and store information in info\n",
    "#collect language names in each group of files (group by filename)\n",
    "\n",
    "langNames = {}\n",
    "\n",
    "for fl in filesname:\n",
    "    print(fl)\n",
    "    langNames[fl] = []\n",
    "    for i in range(len(folders)):\n",
    "        #print(folders[i])\n",
    "        with open(folders[i]+'/'+fl, 'r+',encoding=\"utf8\") as f:\n",
    "            lines= f.readlines() \n",
    "            cols = lines[0].strip().split('\\t')\n",
    "            \n",
    "            for line in lines[1:]:\n",
    "                line = line.strip().split('\\t')\n",
    "                #print(line)\n",
    "                lang = line[0]\n",
    "                langNames[fl].append(lang)\n",
    "                for idx, colname in enumerate(cols[1:]):\n",
    "                    info[fl][colname][lang]=line[idx+1]\n",
    "            #print(cols, '\\n')\n",
    "    assert(len(langNames[fl])== len(set(langNames[fl])))       \n",
    "print(info['f.tsv']['appos']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "104\n",
      "['Afrikaans', 'Akkadian', 'Akuntsu', 'Albanian', 'Amharic', 'AncientGreek', 'Apurinã', 'Arabic', 'Armenian', 'Assyrian', 'Bambara', 'Basque', 'Belarusian', 'Bhojpuri', 'Breton', 'Bulgarian', 'Buryat', 'Cantonese', 'Catalan', 'Chinese', 'Chukot', 'ClassicalChinese', 'Coptic', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Erzya', 'Estonian', 'Faroese', 'Finnish', 'French', 'Gaelic', 'Galician', 'German', 'Gothic', 'Greek', 'Hebrew', 'Hindi', 'HindiEnglish', 'Hungarian', 'Icelandic', 'Indonesian', 'Irish', 'Italian', 'Japanese', 'Karelian', 'Kazakh', 'Khunsari', 'Komi', 'Komi-Permyak', 'Korean', 'Kurmanji', 'Latin', 'Latvian', 'Lithuanian', 'Livvi', 'Maltese', 'Manx', 'Marathi', 'MbyáGuaraní', 'Moksha', 'Mundurukú', 'Naija', 'Nayini', 'NorthSami', 'Norwegian', 'OldChurchSlavonic', 'OldEastSlavic', 'OldFrench', 'OldTurkish', 'Persian', 'Polish', 'Portuguese', 'Romanian', 'Russian', 'Sanskrit', 'Serbian', 'SkoltSami', 'Slovak', 'Slovenian', 'Soi', 'SouthLevantineArabic', 'Spanish', 'Swedish', 'SwedishSign', 'SwissGerman', 'Tagalog', 'Tamil', 'Telugu', 'Thai', 'Tupinambá', 'Turkish', 'TurkishGerman', 'Ukrainian', 'UpperSorbian', 'Urdu', 'Uyghur', 'Vietnamese', 'Warlpiri', 'Welsh', 'Wolof', 'Yoruba']\n"
     ]
    }
   ],
   "source": [
    "print(len(langNames[fl]))\n",
    "print(len(set(langNames[fl])))\n",
    "print(sorted(langNames[fl]))\n",
    "#print(sorted(set(langNames[fl])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['appos', 'cc', 'clf', 'comp', 'comp:aux', 'comp:cleft', 'comp:obj', 'comp:obl', 'comp:pred', 'compound', 'compound:prt', 'compound:redup', 'compound:svc', 'conj', 'conj:appos', 'conj:coord', 'conj:dicto', 'conj:emb', 'conj:obj', 'det', 'det:num', 'discourse', 'dislocated', 'flat', 'flat:foreign', 'flat:name', 'goeswith', 'list', 'mod', 'mod:appos', 'mod:emph', 'mod:num', 'mod:periph', 'mod:poss', 'orphan', 'parataxis', 'parataxis:conj', 'parataxis:discourse', 'parataxis:dislocated', 'parataxis:insert', 'parataxis:obj', 'parataxis:parenth', 'punct', 'reparandum', 'subj', 'total', 'udep', 'unk', 'vocative'])\n"
     ]
    }
   ],
   "source": [
    "print(info['f.tsv'].keys())\n",
    "#' '.join(info['f.tsv']['appos'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0008'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(info['f.tsv']['appos'].get('Arabic',0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f.tsv\n",
      "cat.tsv\n",
      "positive-direction.tsv\n",
      "cf.tsv\n",
      "cfc-dist.tsv\n",
      "cf-dist.tsv\n",
      "cfc.tsv\n",
      "f-dist-noroot.tsv\n",
      "posdircf.tsv\n",
      "posdircfc.tsv\n",
      "fc.tsv\n",
      "f-dist.tsv\n",
      "abs-f-dist-noroot.tsv\n"
     ]
    }
   ],
   "source": [
    "#write combined informations in files of output folder\n",
    "for fl in filesname:\n",
    "    print(fl)\n",
    "    with open(outputFolder+'/'+fl, 'w+',encoding=\"utf8\")as t:\n",
    "        line0 = \"name\"+'\\t'+'\\t'.join(info[fl].keys())\n",
    "        t.write(line0)\n",
    "        for lang in langNames[fl]:\n",
    "            line = lang\n",
    "            for col in colNamesDict[fl]:#for each type (label of columns)\n",
    "                line += '\\t'+str(info[fl][col].get(lang,0))\n",
    "            t.write(line+'\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
